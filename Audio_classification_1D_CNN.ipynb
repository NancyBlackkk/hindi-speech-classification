{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIZZFTBSguFD",
        "outputId": "72bc3a8f-c154-4fbb-b591-ba4daacb5268"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install librosa"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import requests\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "qPrR2F88l4a3"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofUQPLqOHotI",
        "outputId": "b152404b-d08c-40b0-cb04-763516857abd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл загружен: /content/hindi.zip\n",
            "ZIP-файл успешно распакован!\n",
            "Файл загружен: /content/hindi.csv\n"
          ]
        }
      ],
      "source": [
        "zip_url = 'https://github.com/NancyBlackkk/hindi-speech-classification/raw/ba7539879fc9419ec242a2db4b6cf291e8996f27/hindi_audio.zip'\n",
        "csv_url = 'https://github.com/NancyBlackkk/hindi-speech-classification/raw/ba7539879fc9419ec242a2db4b6cf291e8996f27/hindi.csv'\n",
        "\n",
        "data_dir = '/content/'\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "def download_file(url, destination):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        with open(destination, 'wb') as file:\n",
        "            file.write(response.content)\n",
        "        print(f\"Файл загружен: {destination}\")\n",
        "    else:\n",
        "        print(f\"Ошибка при загрузке файла: {url}\")\n",
        "\n",
        "zip_file_path = os.path.join(data_dir, 'hindi.zip')\n",
        "download_file(zip_url, zip_file_path)\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(data_dir)\n",
        "\n",
        "print(\"ZIP-файл успешно распакован!\")\n",
        "\n",
        "csv_file_path = os.path.join(data_dir, 'hindi.csv')\n",
        "download_file(csv_url, csv_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2uSsUS0mXm5",
        "outputId": "c1f95cb6-65b7-44cf-b8c4-5e3b7d680997"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Первые несколько строк меток:\n",
            "                    file_id gender\n",
            "0  common_voice_hi_26042241   male\n",
            "1  common_voice_hi_24026282   male\n",
            "2  common_voice_hi_24026319   male\n",
            "3  common_voice_hi_26019764   male\n",
            "4  common_voice_hi_25579063   male\n"
          ]
        }
      ],
      "source": [
        "labels_df = pd.read_csv(csv_file_path)\n",
        "print(\"Первые несколько строк меток:\")\n",
        "print(labels_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "MdppjI6QK4qw"
      },
      "outputs": [],
      "source": [
        "labels_df['gender'] = labels_df['gender'].map({'male': 0, 'female': 1})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_dir = os.path.join(data_dir, 'hindi')"
      ],
      "metadata": {
        "id": "Iys48kPVW1g1"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_max_mfcc_length(audio_dir):\n",
        "    max_len = 0\n",
        "    for file_name in os.listdir(audio_dir):\n",
        "        if file_name.endswith(\".mp3\"):\n",
        "            mp3_file = os.path.join(audio_dir, file_name)\n",
        "            signal, sr = librosa.load(mp3_file, sr=None)\n",
        "            mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=13)\n",
        "            if mfcc.shape[1] > max_len:\n",
        "                max_len = mfcc.shape[1]\n",
        "    return max_len"
      ],
      "metadata": {
        "id": "aTM-Or-wW59L"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = find_max_mfcc_length(audio_dir)\n",
        "print(f\"Максимальная длина MFCC: {max_len}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUoh47mLXAG7",
        "outputId": "4100cf0e-acf6-468a-ed20-f21623eb9d73"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Максимальная длина MFCC: 892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_noise(signal, noise_factor=0.005):\n",
        "    noise = np.random.randn(len(signal))\n",
        "    augmented_signal = signal + noise_factor * noise\n",
        "    return augmented_signal\n",
        "\n",
        "def pitch_shift(signal, sr, n_steps=2):\n",
        "    return librosa.effects.pitch_shift(signal, sr=sr, n_steps=n_steps)\n",
        "\n",
        "def time_stretch(signal, speed_factor=0.8):\n",
        "    return librosa.effects.time_stretch(signal, rate=speed_factor)\n",
        "\n",
        "def reverse_signal(signal):\n",
        "    return np.flip(signal)"
      ],
      "metadata": {
        "id": "ZMyDCZXlcC1I"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_mfcc_with_augmentation(mp3_file, n_mfcc=13, max_len=max_len, augment=False):\n",
        "    try:\n",
        "        signal, sr = librosa.load(mp3_file, sr=None)\n",
        "\n",
        "        if augment:\n",
        "            if random.random() < 0.25:  # Добавляем шум с вероятностью 25%\n",
        "                signal = add_noise(signal)\n",
        "            if random.random() < 0.25:  # Меняем высоту тона с вероятностью 25%\n",
        "                signal = pitch_shift(signal, sr)\n",
        "            if random.random() < 0.25:  # Меняем скорость воспроизведения с вероятностью 25%\n",
        "                signal = time_stretch(signal)\n",
        "            if random.random() < 0.25:  # Реверсируем сигнал с вероятностью 25%\n",
        "                signal = reverse_signal(signal)\n",
        "\n",
        "        mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=n_mfcc)\n",
        "\n",
        "        if mfcc.shape[1] < max_len:\n",
        "            mfcc = np.pad(mfcc, ((0, 0), (0, max_len - mfcc.shape[1])), mode='constant')\n",
        "\n",
        "        return mfcc\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка при обработке файла {mp3_file}: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "RbRo0ahyXEKl"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_audio_data(audio_dir, labels_df, augment=False):\n",
        "    mfcc_data = []\n",
        "    file_ids = []\n",
        "\n",
        "    for file_name in os.listdir(audio_dir):\n",
        "        if file_name.endswith(\".mp3\"):\n",
        "            mp3_file = os.path.join(audio_dir, file_name)\n",
        "            mfcc = extract_mfcc_with_augmentation(mp3_file, augment=augment)\n",
        "\n",
        "            if mfcc is not None:\n",
        "                mfcc_data.append(mfcc)\n",
        "                file_id = file_name.replace('.mp3', '')\n",
        "                label = labels_df[labels_df['file_id'] == file_id]['gender'].values\n",
        "\n",
        "                if len(label) > 0:\n",
        "                    file_ids.append(file_id)\n",
        "                else:\n",
        "                    print(f\"Метка для файла {file_id} не найдена\")\n",
        "\n",
        "    return np.array(mfcc_data), file_ids"
      ],
      "metadata": {
        "id": "zavrT0tOevUb"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mfcc_data, file_ids = process_audio_data(audio_dir, labels_df)\n",
        "labels = np.array([labels_df[labels_df['file_id'] == file_id]['gender'].values[0] for file_id in file_ids])"
      ],
      "metadata": {
        "id": "-pKigywzk495"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mfcc_data_augmented, file_ids_augmented = process_audio_data(audio_dir, labels_df, augment=True)\n",
        "labels_augmented = np.array([labels_df[labels_df['file_id'] == file_id]['gender'].values[0] for file_id in file_ids_augmented])"
      ],
      "metadata": {
        "id": "R0Gr49Umk9IG"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_combined = np.concatenate((mfcc_data, mfcc_data_augmented), axis=0)\n",
        "train_labels_combined = np.concatenate((labels, labels_augmented), axis=0)"
      ],
      "metadata": {
        "id": "IRMuuQbBlIjC"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data, train_labels, test_labels = train_test_split(train_data_combined, train_labels_combined, test_size=0.25, random_state=42)\n",
        "\n",
        "train_data = torch.tensor(train_data, dtype=torch.float32)\n",
        "test_data = torch.tensor(test_data, dtype=torch.float32)\n",
        "train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
        "test_labels = torch.tensor(test_labels, dtype=torch.long)"
      ],
      "metadata": {
        "id": "ayLy394ZgpYr"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверим размер выборок\n",
        "print(f\"Размер обучающей выборки: {train_data.shape}\")\n",
        "print(f\"Размер тестовой выборки: {test_data.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCJFnlnvj6Mt",
        "outputId": "9dbc6a95-1c90-4b97-8282-bfc33107edcf"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер обучающей выборки: torch.Size([750, 13, 892])\n",
            "Размер тестовой выборки: torch.Size([250, 13, 892])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SingleLayerCNN(nn.Module):\n",
        "    def __init__(self, max_len):\n",
        "        super(SingleLayerCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=13, out_channels=16, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool1d(2)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc1 = None\n",
        "\n",
        "        self._initialize_weights(max_len)\n",
        "\n",
        "    def _initialize_weights(self, max_len):\n",
        "        x = torch.zeros(1, 13, max_len)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        self.output_size = x.size(1)\n",
        "        self.fc1 = nn.Linear(self.output_size, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "sbfyMu5SscpG"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SingleLayerCNN(max_len)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
        "\n",
        "num_epochs = 15\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = model(train_data.permute(0, 1, 2))\n",
        "    loss = criterion(outputs, train_labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_outputs = model(test_data.permute(0, 1, 2))\n",
        "        test_loss = criterion(test_outputs, test_labels)\n",
        "        test_losses.append(test_loss.item())\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    train_accuracy = (predicted == train_labels).float().mean()\n",
        "    train_accuracies.append(train_accuracy.item())\n",
        "\n",
        "    _, test_predicted = torch.max(test_outputs, 1)\n",
        "    test_accuracy = (test_predicted == test_labels).float().mean()\n",
        "    test_accuracies.append(test_accuracy.item())\n",
        "\n",
        "    print(f\"Эпоха [{epoch + 1}/{num_epochs}], Потери: {loss.item():.3f}, Точность (train): {train_accuracy:.3f}, Точность (test): {test_accuracy:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0wJQA9ushMx",
        "outputId": "1479454d-1b38-4622-9cb0-66646767d121"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха [1/15], Потери: 2.685, Точность (train): 0.707, Точность (test): 0.820\n",
            "Эпоха [2/15], Потери: 6.083, Точность (train): 0.839, Точность (test): 0.644\n",
            "Эпоха [3/15], Потери: 6.233, Точность (train): 0.615, Точность (test): 0.780\n",
            "Эпоха [4/15], Потери: 3.119, Точность (train): 0.800, Точность (test): 0.820\n",
            "Эпоха [5/15], Потери: 4.151, Точность (train): 0.827, Точность (test): 0.820\n",
            "Эпоха [6/15], Потери: 3.581, Точность (train): 0.840, Точность (test): 0.808\n",
            "Эпоха [7/15], Потери: 2.065, Точность (train): 0.804, Точность (test): 0.612\n",
            "Эпоха [8/15], Потери: 3.699, Точность (train): 0.605, Точность (test): 0.808\n",
            "Эпоха [9/15], Потери: 1.799, Точность (train): 0.757, Точность (test): 0.820\n",
            "Эпоха [10/15], Потери: 2.223, Точность (train): 0.825, Точность (test): 0.820\n",
            "Эпоха [11/15], Потери: 2.433, Точность (train): 0.851, Точность (test): 0.820\n",
            "Эпоха [12/15], Потери: 2.147, Точность (train): 0.836, Точность (test): 0.832\n",
            "Эпоха [13/15], Потери: 1.501, Точность (train): 0.809, Точность (test): 0.832\n",
            "Эпоха [14/15], Потери: 1.887, Точность (train): 0.751, Точность (test): 0.844\n",
            "Эпоха [15/15], Потери: 1.815, Точность (train): 0.736, Точность (test): 0.848\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}